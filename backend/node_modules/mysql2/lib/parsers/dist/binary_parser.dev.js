'use strict';

var FieldFlags = require('../constants/field_flags.js');

var Charsets = require('../constants/charsets.js');

var Types = require('../constants/types.js');

var helpers = require('../helpers');

var genFunc = require('generate-function');

var parserCache = require('./parser_cache.js');

var typeNames = [];

for (var t in Types) {
  typeNames[Types[t]] = t;
}

function readCodeFor(field, config, options, fieldNum) {
  var supportBigNumbers = Boolean(options.supportBigNumbers || config.supportBigNumbers);
  var bigNumberStrings = Boolean(options.bigNumberStrings || config.bigNumberStrings);
  var timezone = options.timezone || config.timezone;
  var dateStrings = options.dateStrings || config.dateStrings;
  var unsigned = field.flags & FieldFlags.UNSIGNED;

  switch (field.columnType) {
    case Types.TINY:
      return unsigned ? 'packet.readInt8();' : 'packet.readSInt8();';

    case Types.SHORT:
      return unsigned ? 'packet.readInt16();' : 'packet.readSInt16();';

    case Types.LONG:
    case Types.INT24:
      // in binary protocol int24 is encoded in 4 bytes int32
      return unsigned ? 'packet.readInt32();' : 'packet.readSInt32();';

    case Types.YEAR:
      return 'packet.readInt16()';

    case Types.FLOAT:
      return 'packet.readFloat();';

    case Types.DOUBLE:
      return 'packet.readDouble();';

    case Types.NULL:
      return 'null;';

    case Types.DATE:
    case Types.DATETIME:
    case Types.TIMESTAMP:
    case Types.NEWDATE:
      if (helpers.typeMatch(field.columnType, dateStrings, Types)) {
        return "packet.readDateTimeString(".concat(parseInt(field.decimals, 10), ");");
      }

      return "packet.readDateTime(".concat(helpers.srcEscape(timezone), ");");

    case Types.TIME:
      return 'packet.readTimeString()';

    case Types.DECIMAL:
    case Types.NEWDECIMAL:
      if (config.decimalNumbers) {
        return 'packet.parseLengthCodedFloat();';
      }

      return 'packet.readLengthCodedString("ascii");';

    case Types.GEOMETRY:
      return 'packet.parseGeometryValue();';

    case Types.JSON:
      // Since for JSON columns mysql always returns charset 63 (BINARY),
      // we have to handle it according to JSON specs and use "utf8",
      // see https://github.com/sidorares/node-mysql2/issues/409
      return config.jsonStrings ? 'packet.readLengthCodedString("utf8")' : 'JSON.parse(packet.readLengthCodedString("utf8"));';

    case Types.LONGLONG:
      if (!supportBigNumbers) {
        return unsigned ? 'packet.readInt64JSNumber();' : 'packet.readSInt64JSNumber();';
      }

      if (bigNumberStrings) {
        return unsigned ? 'packet.readInt64String();' : 'packet.readSInt64String();';
      }

      return unsigned ? 'packet.readInt64();' : 'packet.readSInt64();';

    default:
      if (field.characterSet === Charsets.BINARY) {
        return 'packet.readLengthCodedBuffer();';
      }

      return "packet.readLengthCodedString(fields[".concat(fieldNum, "].encoding)");
  }
}

function compile(fields, options, config) {
  var parserFn = genFunc();
  var nullBitmapLength = Math.floor((fields.length + 7 + 2) / 8);

  function wrap(field, packet) {
    return {
      type: typeNames[field.columnType],
      length: field.columnLength,
      db: field.schema,
      table: field.table,
      name: field.name,
      string: function string() {
        var encoding = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : field.encoding;

        if (field.columnType === Types.JSON && encoding === field.encoding) {
          // Since for JSON columns mysql always returns charset 63 (BINARY),
          // we have to handle it according to JSON specs and use "utf8",
          // see https://github.com/sidorares/node-mysql2/issues/1661
          console.warn("typeCast: JSON column \"".concat(field.name, "\" is interpreted as BINARY by default, recommended to manually set utf8 encoding: `field.string(\"utf8\")`"));
        }

        if ([Types.DATETIME, Types.NEWDATE, Types.TIMESTAMP, Types.DATE].includes(field.columnType)) {
          return packet.readDateTimeString(parseInt(field.decimals, 10));
        }

        if (field.columnType === Types.TINY) {
          var unsigned = field.flags & FieldFlags.UNSIGNED;
          return String(unsigned ? packet.readInt8() : packet.readSInt8());
        }

        if (field.columnType === Types.TIME) {
          return packet.readTimeString();
        }

        return packet.readLengthCodedString(encoding);
      },
      buffer: function buffer() {
        return packet.readLengthCodedBuffer();
      },
      geometry: function geometry() {
        return packet.parseGeometryValue();
      }
    };
  }

  parserFn('(function(){');
  parserFn('return class BinaryRow {');
  parserFn('constructor() {');
  parserFn('}');
  parserFn('next(packet, fields, options) {');

  if (options.rowsAsArray) {
    parserFn("const result = new Array(".concat(fields.length, ");"));
  } else {
    parserFn('const result = {};');
  } // Global typeCast


  if (typeof config.typeCast === 'function' && typeof options.typeCast !== 'function') {
    options.typeCast = config.typeCast;
  }

  parserFn('packet.readInt8();'); // status byte

  for (var i = 0; i < nullBitmapLength; ++i) {
    parserFn("const nullBitmaskByte".concat(i, " = packet.readInt8();"));
  }

  var lvalue = '';
  var currentFieldNullBit = 4;
  var nullByteIndex = 0;
  var fieldName = '';
  var tableName = '';

  for (var _i = 0; _i < fields.length; _i++) {
    fieldName = helpers.fieldEscape(fields[_i].name); // parserFn(`// ${fieldName}: ${typeNames[fields[i].columnType]}`);

    if (typeof options.nestTables === 'string') {
      lvalue = "result[".concat(helpers.fieldEscape(fields[_i].table + options.nestTables + fields[_i].name), "]");
    } else if (options.nestTables === true) {
      tableName = helpers.fieldEscape(fields[_i].table);
      parserFn("if (!result[".concat(tableName, "]) result[").concat(tableName, "] = {};"));
      lvalue = "result[".concat(tableName, "][").concat(fieldName, "]");
    } else if (options.rowsAsArray) {
      lvalue = "result[".concat(_i.toString(10), "]");
    } else {
      lvalue = "result[".concat(fieldName, "]");
    }

    parserFn("if (nullBitmaskByte".concat(nullByteIndex, " & ").concat(currentFieldNullBit, ") "));
    parserFn("".concat(lvalue, " = null;"));
    parserFn('else {');

    if (options.typeCast === false) {
      parserFn("".concat(lvalue, " = packet.readLengthCodedBuffer();"));
    } else {
      var fieldWrapperVar = "fieldWrapper".concat(_i);
      parserFn("const ".concat(fieldWrapperVar, " = wrap(fields[").concat(_i, "], packet);"));
      var readCode = readCodeFor(fields[_i], config, options, _i);

      if (typeof options.typeCast === 'function') {
        parserFn("".concat(lvalue, " = options.typeCast(").concat(fieldWrapperVar, ", function() { return ").concat(readCode, " });"));
      } else {
        parserFn("".concat(lvalue, " = ").concat(readCode, ";"));
      }
    }

    parserFn('}');
    currentFieldNullBit *= 2;

    if (currentFieldNullBit === 0x100) {
      currentFieldNullBit = 1;
      nullByteIndex++;
    }
  }

  parserFn('return result;');
  parserFn('}');
  parserFn('};')('})()');

  if (config.debug) {
    helpers.printDebugWithCode('Compiled binary protocol row parser', parserFn.toString());
  }

  return parserFn.toFunction({
    wrap: wrap
  });
}

function getBinaryParser(fields, options, config) {
  return parserCache.getParser('binary', fields, options, config, compile);
}

module.exports = getBinaryParser;